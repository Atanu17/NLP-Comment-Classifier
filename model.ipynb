{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55616ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d9df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import nlp_utils\n",
    "import contractions # I'll -> I will \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc885f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0f46f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599999 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target          id                          date      flag  \\\n",
       "0             0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "1             0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "2             0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "3             0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4             0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "...         ...         ...                           ...       ...   \n",
       "1599994       4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599995       4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996       4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997       4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998       4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                       comment_text  \n",
       "0          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "1               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "2                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "3                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "4               joy_wolf                      @Kwesidei not the whole crew   \n",
       "...                  ...                                                ...  \n",
       "1599994  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599995      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599996           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599997     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599998   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1599999 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns =['target', 'id', 'date', 'flag', 'user', 'comment_text']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a70a49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599999 entries, 0 to 1599998\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count    Dtype \n",
      "---  ------        --------------    ----- \n",
      " 0   target        1599999 non-null  int64 \n",
      " 1   id            1599999 non-null  int64 \n",
      " 2   date          1599999 non-null  object\n",
      " 3   flag          1599999 non-null  object\n",
      " 4   user          1599999 non-null  object\n",
      " 5   comment_text  1599999 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "720db3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target          0\n",
       "id              0\n",
       "date            0\n",
       "flag            0\n",
       "user            0\n",
       "comment_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b12e8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    799999\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d94512",
   "metadata": {},
   "source": [
    "### Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a323ddf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@octolinz16 It it counts, idk why I did either. you never talk to me anymore '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment_text'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54d9e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5d1176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing special characters\n",
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "punc_lower = lambda x : re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "remove_n = lambda x: re.sub(\"\\n\", \" \", x)\n",
    "remove_non_ascii = lambda x: re.sub(r'[^\\x00-\\x7f]', r' ', x)\n",
    "df['comment_text'] = df['comment_text'].map(alphanumeric).map(punc_lower).map(remove_n).map(remove_non_ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df21e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Target_comment_df = df.loc[:, ['id','comment_text', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0647fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467810672</td>\n",
       "      <td>is upset that he can t update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1467810917</td>\n",
       "      <td>kenichan i dived many times for the ball  man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1467811184</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1467811193</td>\n",
       "      <td>nationwideclass no  it s not behaving at all ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1467811372</td>\n",
       "      <td>kwesidei not the whole crew</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>2193601966</td>\n",
       "      <td>just woke up  having no school is the best fee...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>2193601969</td>\n",
       "      <td>thewdb com   very cool to hear old walt interv...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>2193601991</td>\n",
       "      <td>are you ready for your mojo makeover  ask me f...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>2193602064</td>\n",
       "      <td>happy   birthday to my boo of alll time    tup...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>2193602129</td>\n",
       "      <td>happy  charitytuesday  thenspcc  sparkscharity...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599999 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  target\n",
       "0        1467810672  is upset that he can t update his facebook by ...       0\n",
       "1        1467810917   kenichan i dived many times for the ball  man...       0\n",
       "2        1467811184    my whole body feels itchy and like its on fire        0\n",
       "3        1467811193   nationwideclass no  it s not behaving at all ...       0\n",
       "4        1467811372                       kwesidei not the whole crew        0\n",
       "...             ...                                                ...     ...\n",
       "1599994  2193601966  just woke up  having no school is the best fee...       4\n",
       "1599995  2193601969  thewdb com   very cool to hear old walt interv...       4\n",
       "1599996  2193601991  are you ready for your mojo makeover  ask me f...       4\n",
       "1599997  2193602064  happy   birthday to my boo of alll time    tup...       4\n",
       "1599998  2193602129  happy  charitytuesday  thenspcc  sparkscharity...       4\n",
       "\n",
       "[1599999 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target_comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d498af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73c080eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing dataset using wordcloud\n",
    "def wordcloud(df, label):\n",
    "    subset = df[df[label] == 0]\n",
    "    text = subset.comment_text.values\n",
    "    wc = WordCloud(background_color = \"black\", max_words = 2000)\n",
    "    wc.generate(\" \".join(text))\n",
    "    plt.figure(figsize = (20, 20))\n",
    "    plt.subplot(221)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Words frequented in {}\".format(label), fontsize = 20)\n",
    "    plt.imshow(wc.recolor(colormap = 'gist_earth', random_state = 244), alpha = 0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd95e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud(Target_comment_df, 'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e003d0",
   "metadata": {},
   "source": [
    "#### ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfecc98b",
   "metadata": {},
   "source": [
    "- balancing target column in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6beb8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    799999\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target_comment_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ec4c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "Target_comment_balanced_4 = Target_comment_df[Target_comment_df['target'] == 4].iloc[0:7999, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bee649c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Target_comment_balanced_0 = Target_comment_df[Target_comment_df['target'] == 0].iloc[0:7999, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50db3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "Target_comment_balanced = pd.concat([Target_comment_balanced_4, Target_comment_balanced_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba55cab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    7999\n",
       "0    7999\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target_comment_balanced['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515fd6a9",
   "metadata": {},
   "source": [
    "####  ML parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f2660ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve, fbeta_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk import ngrams, bigrams, trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbcbd1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_tf_train_test(dataframe, label, vectorizer, ngram):\n",
    "    \n",
    "    # Split the data into X and y data sets\n",
    "    X = dataframe.comment_text\n",
    "    y = dataframe[label]\n",
    "    \n",
    "    # Split data in train and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 50)\n",
    "    \n",
    "    # Using vectorizer to remove stopwords\n",
    "    cv1 = vectorizer(ngram_range = (ngram), stop_words = 'english')\n",
    "    \n",
    "    # Transforming x-train and x-test\n",
    "    X_train_cv1 = cv1.fit_transform(X_train)\n",
    "    X_test_cv1 = cv1.transform(X_test)\n",
    "    \n",
    "    ### ML models\n",
    "    \n",
    "    ## logistic regression \n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train_cv1, y_train)\n",
    "    \n",
    "    ## k-nearest neighbours \n",
    "    knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "    knn.fit(X_train_cv1, y_train)\n",
    "    \n",
    "    ## Naive Bayes\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(X_train_cv1, y_train)\n",
    "    \n",
    "    ## Multinomial Naive Bayes\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X_train_cv1, y_train)\n",
    "    \n",
    "    ## Support vector machine\n",
    "    svm_model = LinearSVC()\n",
    "    svm_model.fit(X_train_cv1, y_train)\n",
    "    \n",
    "    ## Random forest\n",
    "    randomforest = RandomForestClassifier(n_estimators = 100, random_state = 50)\n",
    "    randomforest.fit(X_train_cv1, y_train)\n",
    "    \n",
    "    \"\"\"\n",
    "     f1_score_data = {'F1 Score':[f1_score(lr.predict(X_test_cv1), y_test), \n",
    "                                f1_score(knn.predict(X_test_cv1), y_test), \n",
    "                                f1_score(bnb.predict(X_test_cv1), y_test), \n",
    "                                f1_score(mnb.predict(X_test_cv1), y_test), \n",
    "                                f1_score(svm_model.predict(X_test_cv1), y_test),\n",
    "                                f1_score(randomforest.predict(X_test_cv1), y_test)]}\n",
    "    \"\"\"\n",
    "    f1_score_data = {'F1 Score':[f1_score(lr.predict(X_test_cv1), y_test, pos_label = 4), \n",
    "                                f1_score(knn.predict(X_test_cv1), y_test, pos_label = 4), \n",
    "                                f1_score(bnb.predict(X_test_cv1), y_test, pos_label = 4), \n",
    "                                f1_score(mnb.predict(X_test_cv1), y_test, pos_label = 4), \n",
    "                                f1_score(svm_model.predict(X_test_cv1), y_test, pos_label = 4),\n",
    "                                f1_score(randomforest.predict(X_test_cv1), y_test, pos_label = 4)]}\n",
    "    ## Saving f1 score results into a dataframe\n",
    "    df_f1 = pd.DataFrame(f1_score_data, index = ['LR','KNN','BNB', 'MNB','SVM','RF'])\n",
    "    return df_f1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a281e45",
   "metadata": {},
   "source": [
    "#### Evaluating model performance using evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcc2a365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Score(Target)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.732245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.547905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BNB</th>\n",
       "      <td>0.698588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNB</th>\n",
       "      <td>0.705017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.720921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.716732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     F1 Score(Target)\n",
       "LR           0.732245\n",
       "KNN          0.547905\n",
       "BNB          0.698588\n",
       "MNB          0.705017\n",
       "SVM          0.720921\n",
       "RF           0.716732"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target_comment_cv = cv_tf_train_test(Target_comment_balanced, 'target', TfidfVectorizer, (1, 1))\n",
    "Target_comment_cv.rename(columns = {'F1 Score' : 'F1 Score(Target)'}, inplace = True)\n",
    "Target_comment_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99d6b98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 0, ..., 0, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Target_comment_balanced.comment_text\n",
    "y = Target_comment_balanced['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "tfv = TfidfVectorizer(ngram_range = (1,1), stop_words = 'english')\n",
    "    \n",
    "\n",
    "X_train_fit = tfv.fit_transform(X_train)\n",
    "X_test_fit = tfv.transform(X_test)\n",
    "    \n",
    "randomforest = RandomForestClassifier(n_estimators = 100, random_state = 50)\n",
    "randomforest.fit(X_train_fit, y_train)\n",
    "randomforest.predict(X_test_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72045302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2602204])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing model\n",
    "\n",
    "c1 = [\"I killed the insect and ate it\"]\n",
    "c1_vect = tfv.transform(c1)\n",
    "randomforest.predict_proba(c1_vect)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa1eb797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing model\n",
    "\n",
    "c2 = [\"I love dogs\"]\n",
    "c2_vect = tfv.transform(c2)\n",
    "randomforest.predict_proba(c2_vect)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e9272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
